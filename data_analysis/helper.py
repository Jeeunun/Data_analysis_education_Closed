import numpy as np
from pandas import DataFrame
from sklearn.impute import SimpleImputer

# ê²°ì¸¡ì¹˜ê²½ê³„ êµ¬í•˜ê¸° í•¨ìˆ˜
def getIq(field):
    q1 = field.quantile(q=0.25)
    q3 = field.quantile(q=0.75)
    iqr = q3 - q1
    í•˜í•œ = q1 - 1.5 * iqr
    ìƒí•œ = q3 + 1.5 * iqr
    ê²°ì¸¡ì¹˜ê²½ê³„ = [í•˜í•œ, ìƒí•œ]
    return ê²°ì¸¡ì¹˜ê²½ê³„

# ì´ìƒì¹˜ë¥¼ ê²°ì¸¡ì¹˜ë¡œ ë³€ê²½ í•¨ìˆ˜
def replaceOutlier(df, fieldName):
    cdf = df.copy()

    # fieldNameì´ Listê°€ ì•„ë‹ˆë©´ Listë¡œ ë³€í™˜
    if not isinstance(fieldName, list):
        fieldName = [fieldName]

    for f in fieldName:
        ê²°ì¸¡ì¹˜ê²½ê³„ = getIq(cdf[f])
        cdf.loc[cdf[f] < ê²°ì¸¡ì¹˜ê²½ê³„[0], f] = np.nan
        cdf.loc[cdf[f] > ê²°ì¸¡ì¹˜ê²½ê³„[1], f] = np.nan

    return cdf

# ê²°ì¸¡ì¹˜ì— ëŒ€í•œ ì²˜ë¦¬ í•¨ìˆ˜
def replaceMissingValue(df):
    imr = SimpleImputer(missing_values=np.nan, strategy='mean')
    df_imr = imr.fit_transform(df.values)
    re_df = DataFrame(df_imr, index=df.index, columns=df.columns)
    return re_df


# stopwords ì§€ìš°ëŠ” í•¨ìˆ˜ [ì›Œë“œí´ë¼ìš°ë“œ]
def clearStopwords(nouns, stopwords_file_path="wordcloud/stopwords-ko.txt"):
    with open(stopwords_file_path, 'r', encoding='utf-8') as f:
        stopwords = f.readlines()

        # stopwordsì—ì„œ ê³µë°± ì§€ìš°ê³  ë¦¬ìŠ¤íŠ¸ë¡œ
        for i,v in enumerate(stopwords):
            stopwords[i] = v.strip()

        data_set = []

        for v in nouns:
            if v not in stopwords:
                data_set.append(v)

        return data_set
    


# ì‹ ë¢°êµ¬ê°„ í•¨ìˆ˜
def get_confidence_interval(data, clevel=0.95):
    n = len(data)                                                       #ìƒ˜í”Œì‚¬ì´ì¦ˆ
    dof = n-1                                                           #ììœ ë„
    sample_mean = data.mean()                                           #í‘œë³¸í‰ê· 
    sample_std = data.std(ddof=1)                                       #í‘œë³¸í‘œì¤€í¸ì°¨
    sample_std_error = sample_std / sqrt(n)                             #í‘œë³¸í‘œì¤€ì˜¤ì°¨
    #ì‹ ë¢°êµ¬ê°„
    cmin, cmax = t.interval(clevel, dof, sample_mean, sample_std_error )
    return(cmin, cmax)

# <ì¼ì›ë¶„ì‚°ë¶„ì„> ì •ê·œì„± ê²€ì¦ í•¨ìˆ˜
from pandas import DataFrame, MultiIndex
from scipy.stats import shapiro, normaltest, ks_2samp

def normality_test(*any):
    names = []

    result = {
        'statistic' : [],
        'p-value' : [],
        'result' : []
    }

    for i in any:
        s, p = shapiro(i)
        result['statistic'].append(s)
        result['p-value'].append(p)
        result['result'].append(p > 0.05)
        names.append(('ì •ê·œì„±', 'shapiro', i.name))

    for i in any:
        s, p = normaltest(i)
        result['statistic'].append(s)
        result['p-value'].append(p)
        result['result'].append(p > 0.05)
        names.append(('ì •ê·œì„±', 'normaltest', i.name))  

    n = len(any)

    for i in range(0,n):
        j = i + 1 if i < n-1 else 0

        s, p = ks_2samp(any[i], any[j])
        result['statistic'].append(s)
        result['p-value'].append(p)
        result['result'].append(p > 0.05)
        names.append(('ì •ê·œì„±', 'ks_2samp', f'{any[i].name} vs {any[j].name}'))

    return DataFrame(result, index=MultiIndex.from_tuples(names, name = ['condition','test','field']))     


# <ì¼ì›ë¶„ì‚°ë¶„ì„> ë“±ë¶„ì‚°ì„± ê²€ì¦ í•¨ìˆ˜
from scipy.stats import bartlett, fligner, levene

def equal_variance_test(*any):
    s1, p1 = bartlett(*any)
    s2, p2 = fligner(*any)
    s3, p3 = levene(*any)

    names = []

    for i in any:
        names.append(i.name)

    fix = " vs "
    name = fix.join(names)
    index = [['ë“±ë¶„ì‚°ì„±', 'Bartlett', name], ['ë“±ë¶„ì‚°ì„±', 'Fligner', name], ['ë“±ë¶„ì‚°ì„±', 'Levene', name]]
    
    df = DataFrame({
        'statistic': [s1, s2, s3],
        'p-value': [p1, p2, p3],
        'equal-var': [p1 > 0.05, p2 > 0.05, p3 > 0.05]
    }, index=MultiIndex.from_tuples(index, names=['condition', 'test','field']))

    return df

# <ì¼ì›ë¶„ì‚°ë¶„ì„> ë…ë¦½ì„± ê²€ì¦ í•¨ìˆ˜
from pandas import DataFrame
from scipy.stats import chi2_contingency

def independence_test(*any):
    df = DataFrame(any).T
    result = chi2_contingency(df) #result = ê°ì²´
    
    names = []
    for i in any:
        names.append(i.name)

    fix = " vs "
    name = fix.join(names)

    index = [['ë…ë¦½ì„±','chi2', name]]

    df = DataFrame({
        'statistic' : [result.statistic],
        'p-value' : [result.pvalue],
        'result' : [result.pvalue > 0.05]
    }, index = MultiIndex.from_tuples(index, names=['condition','test','field']))
    
    return df

# <ì¼ì›ë¶„ì‚°ë¶„ì„> ëª¨ë“  ì¡°ê±´ì„± ê²€ì‚¬ í•¨ìˆ˜
from pandas import concat

def all_test(*any):
    return concat([normality_test(*any), equal_variance_test(*any), independence_test(*any)])


# ì—¬ëŸ¬ë³€ìˆ˜ì˜ ìƒê´€ë¶„ì„ = ìƒê´€ë„í–‰ë ¬ ë°˜ë³µë¬¸ í•¨ìˆ˜
from scipy.stats import t, pearsonr


def pearson_r(df):
    names = df.columns
    n=len(names)
    pv=0.05

    data = []

    for i in range(0,n):
        j = i+1 if i<n-1 else 0

        fields = names[i] + 'vs' + names[j]
        s, p = pearsonr(df[names[i]], df[names[j]])
        result = p < pv

        data.append({'fields': fields, 'statistic': s, 'pvalue': p, 'result': result})

    rdf = DataFrame(data)
    rdf.set_index('fields', inplace=True)

    return rdf

# ìŠ¤í”¼ì–´ë§Œ ìƒê´€ë¶„ì„
from scipy.stats import spearmanr
def spearman_r(df):
    names = df.columns
    n = len(names)
    pv = 0.05

    data = []

    for i in range(0, n):
        # ê¸°ë³¸ì ìœ¼ë¡œ i ë‹¤ìŒ ìœ„ì¹˜ë¥¼ ì˜ë¯¸í•˜ì§€ë§Œ iê°€ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ì¼ ê²½ìš° 0ìœ¼ë¡œ ì„¤ì •
        j = i + 1 if i < n - 1 else 0

        fields = names[i] + ' vs ' + names[j]
        s, p = spearmanr(df[names[i]], df[names[j]])
        result = p < pv

        data.append({'fields': fields, 'statistic': s, 'pvalue': p, 'result': result})

    rdf = DataFrame(data)
    rdf.set_index('fields', inplace=True)
    
    return rdf


# íšŒê·€ë¶„ì„ ê²°ê³¼ë³´ê³  í•¨ìˆ˜
from statsmodels.formula.api import ols
from statsmodels.stats.outliers_influence import variance_inflation_factor

def ext_ols(data, y, x):
    """
    íšŒê·€ë¶„ì„ì„ ìˆ˜í•´í•œë‹¤.

    Parameters
    -------
    - data : ë°ì´í„° í”„ë ˆì„
    - y: ì¢…ì†ë³€ìˆ˜ ì´ë¦„
    - x: ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ë“¤(ë¦¬ìŠ¤íŠ¸)
    """

    # ë…ë¦½ë³€ìˆ˜ì˜ ì´ë¦„ì´ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if type(x) != list:
        x = [x]

    # ì¢…ì†ë³€ìˆ˜~ë…ë¦½ë³€ìˆ˜1+ë…ë¦½ë³€ìˆ˜2+ë…ë¦½ë³€ìˆ˜3+... í˜•íƒœì˜ ì‹ì„ ìƒì„±
    expr = "%s~%s" % (y, "+".join(x))

    # íšŒê·€ëª¨ë¸ ìƒì„±
    model = ols(expr, data=data)
    # ë¶„ì„ ìˆ˜í–‰
    fit = model.fit()

    # íŒŒì´ì¬ ë¶„ì„ê²°ê³¼ë¥¼ ë³€ìˆ˜ì— ì €ì¥í•œë‹¤.
    summary = fit.summary()

    # ì²« ë²ˆì§¸, ì„¸ ë²ˆì§¸ í‘œì˜ ë‚´ìš©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¶„í•´
    my = {}

    for k in range(0, 3, 2):
        items = summary.tables[k].data
        # print(items)

        for item in items:
            # print(item)
            n = len(item)

            for i in range(0, n, 2):
                key = item[i].strip()[:-1]
                value = item[i+1].strip()

                if key and value:
                    my[key] = value

    # ë‘ ë²ˆì§¸ í‘œì˜ ë‚´ìš©ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë¶„í•´í•˜ì—¬ myì— ì¶”ê°€
    my['variables'] = []
    name_list = list(data.columns)
    print(name_list)

    for i, v in enumerate(summary.tables[1].data):
        if i == 0:
            continue

        # ë³€ìˆ˜ì˜ ì´ë¦„
        name = v[0].strip()
        
        vif = 0

        # 0ë²ˆì§¸ì¸ InterceptëŠ” ì œì™¸
        if name in name_list:
            #ë³€ìˆ˜ì˜ ì´ë¦„ ëª©ë¡ì—ì„œ í˜„ì¬ ë³€ìˆ˜ê°€ ëª‡ ë²ˆì§¸ í•­ëª©ì¸ì§€ ì°¾ê¸°
            j = name_list.index(name)
            vif = variance_inflation_factor(data, j)

        my['variables'].append({
            "name": name,
            "coef": v[1].strip(),
            "std err": v[2].strip(),
            "t": v[3].strip(),
            "P-value": v[4].strip(),
            "Beta": 0,
            "VIF": vif,
        })

    # ê²°ê³¼í‘œë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ êµ¬ì„±
    mylist = []
    yname_list = []
    xname_list = []

    for i in my['variables']:
        if i['name'] == 'Intercept':
            continue

        yname_list.append(y)
        xname_list.append(i['name'])

        item = {
            "B": i['coef'],
            "í‘œì¤€ì˜¤ì°¨": i['std err'],
            "Î²": i['Beta'],
            "t": "%s*" % i['t'],
            "ìœ ì˜í™•ë¥ ": i['P-value'],
            "VIF": i["VIF"]
        }

        mylist.append(item)

    table = DataFrame(mylist,
                   index=MultiIndex.from_arrays([yname_list, xname_list], names=['ì¢…ì†ë³€ìˆ˜', 'ë…ë¦½ë³€ìˆ˜']))
    
    # ë¶„ì„ê²°ê³¼
    result = "ğ‘…(%s), ğ‘…^2(%s), ğ¹(%s), ìœ ì˜í™•ë¥ (%s), Durbin-Watson(%s)" % (my['R-squared'], my['Adj. R-squared'], my['F-statistic'], my['Prob (F-statistic)'], my['Durbin-Watson'])

    # ëª¨í˜• ì í•©ë„ ë³´ê³ 
    goodness = "%sì— ëŒ€í•˜ì—¬ %së¡œ ì˜ˆì¸¡í•˜ëŠ” íšŒê·€ë¶„ì„ì„ ì‹¤ì‹œí•œ ê²°ê³¼, ì´ íšŒê·€ëª¨í˜•ì€ í†µê³„ì ìœ¼ë¡œ %s(F(%s,%s) = %s, p < 0.05)." % (y, ",".join(x), "ìœ ì˜í•˜ë‹¤" if float(my['Prob (F-statistic)']) < 0.05 else "ìœ ì˜í•˜ì§€ ì•Šë‹¤", my['Df Model'], my['Df Residuals'], my['F-statistic'])

    # ë…ë¦½ë³€ìˆ˜ ë³´ê³ 
    varstr = []

    for i, v in enumerate(my['variables']):
        if i == 0:
            continue
        
        s = "%sì˜ íšŒê·€ê³„ìˆ˜ëŠ” %s(p%s0.05)ë¡œ, %sì— ëŒ€í•˜ì—¬ %s."
        k = s % (v['name'], v['coef'], "<" if float(v['P-value']) < 0.05 else '>', y, 'ìœ ì˜ë¯¸í•œ ì˜ˆì¸¡ë³€ì¸ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤' if float(v['P-value']) < 0.05 else 'ìœ ì˜í•˜ì§€ ì•Šì€ ì˜ˆì¸¡ë³€ì¸ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ë‹¤')

        varstr.append(k)

    # ë¦¬í„´
    return (model, fit, summary, table, result, goodness, varstr)